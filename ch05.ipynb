{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383f4fb1",
   "metadata": {},
   "source": [
    "# 5章 リカレントニューラルネットワーク(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b3a21",
   "metadata": {},
   "source": [
    "## 5.1 確率と言語モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd0db7",
   "metadata": {},
   "source": [
    "### 5.1.1 word2vecを確率の視点から眺める"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ccc67c",
   "metadata": {},
   "source": [
    "### 5.1.2 言語モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d1df7",
   "metadata": {},
   "source": [
    "#### 言語モデル\n",
    "単語の並びに対してそれがどれだけ起こりえるのかという確率を与える．この確率は音声認識や機械翻訳が文章として自然であるかどうかを判断する際などに用いることができる．\n",
    "#### 同時確率\n",
    "$$\n",
    "P(w_1, ..., w_m)\n",
    "$$\n",
    "複数の事象が同時に起こる確率\n",
    "#### 同時確率を事後確率で分解する\n",
    "$$\n",
    "P(w_1, ..., w_m) = P(w_m|w_1, ..., w_{m-1})P(w_{m-1}|w_1, ..., w_{m-2})\n",
    "...P(w_3|w_1, w_2)P(w_2|w_1)P(w_1)\n",
    "= \\prod_{t=1}^{m}P(w_t|w_1, ..., w_{t-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da19d8",
   "metadata": {},
   "source": [
    "### 5.1.3 CBOWモデルを言語モデルに？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b62e7",
   "metadata": {},
   "source": [
    "コンテキストのサイズをある値に限定することで近似的に表す．\n",
    "\n",
    "#### word2vecのCBOWモデルを言語モデルに\n",
    "### $$ \n",
    "P(w_1, ..., w_m) = \\prod_{t=1}^{m}P(w_t|w_1, ..., w_{t-1})～\\prod_{t=1}^{m}P(w_t|w_{t-2}, w_{t-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae782e0",
   "metadata": {},
   "source": [
    "#### マルコフ性\n",
    "未来の状態が現在の状態だけに依存して決まること．ある事象の確率がその直前のN個の事象だけに依存するとき，「N階マルコフ連鎖」と言う．\n",
    "#### CBOWモデルはコンテキスト内の単語の並びを無視する\n",
    "CBOWモデルの中間層では単語ベクトルの和が求められるため，コンテキストの単語の並び方が無視される．\n",
    "\n",
    "コンテキストの単語ベクトルを中間層において「連結」することが考えられる．一方で連結するアプローチをとれば，コンテキストのサイズに比例して重みパラメータが増える．それは歓迎されない．\n",
    "\n",
    "#### RNN\n",
    "上のジレンマを解消するのがRNN（リカレントニューラルネットワーク）である．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a15299c",
   "metadata": {},
   "source": [
    "## 5.2 RNNとは"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1672a62",
   "metadata": {},
   "source": [
    "#### 直訳すると．．．\n",
    "何度も繰り返し起こること，再発するニューラルネットワーク，循環するニューラルネットワーク．\n",
    "る．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b3f9a",
   "metadata": {},
   "source": [
    "### 5.2.1 循環するニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff35d7",
   "metadata": {},
   "source": [
    "#### 閉じた経路を持つ\n",
    "ループ経路を持つことで，データは絶えず循環することができる．そしてデータが循環することにより，過去の情報を記憶しながら，最新のデータへと更新され"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7e35d3",
   "metadata": {},
   "source": [
    "### 5.2.2 ループの展開"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d191b",
   "metadata": {},
   "source": [
    "#### 2つの入力（そのレイヤの入力，一つ前のRNNレイヤからの出力）を元にその時刻の出力が計算される\n",
    "### $$\n",
    "h_1 = tanh(h_{t-1}W_h+x_tW_x+b)\n",
    "$$\n",
    "\n",
    "- $W_x$: 入力xを出力hに変換するための重み\n",
    "- $W_h$: ひとつ前のRNNの出力を次時刻の出力に変換するための重み\n",
    "- $b$: バイアス\n",
    "\n",
    "#### 状態を持つレイヤ，メモリ（記憶力）を持つレイヤ\n",
    "RNNはhという状態を持つ．\n",
    "\n",
    "#### 隠れ状態，隠れ状態ベクトル\n",
    "RNNのhは「状態」を記憶し，時間が1ステップ（1単位）進むに従い，上記の式の形で計算が行われて更新していく．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761d591",
   "metadata": {},
   "source": [
    "### 5.2.3 Backpropagation Through Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b3320",
   "metadata": {},
   "source": [
    "#### BPTT\n",
    "Backpropagation Through Timeの略称．ループを展開した後のRNNは（通常の）誤差逆伝播法を使える．ここでの誤差逆伝播法は，「時間方向に展開したニューラルネットワークの誤差逆伝播法」となる．\n",
    "\n",
    "#### RNNの学習時の問題\n",
    "時系列データの時間サイズが大きくなると同時に，BPTTで消費するコンピュータの計算リソースが増加すること．また時間サイズが長くなれば，逆伝播時の勾配が不安定になることも考えられる．時系列データの長さに応じて増加するコンピュータのメモリ使用量も考える必要がある．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921ce1da",
   "metadata": {},
   "source": [
    "### 5.2.4 Truncated BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe6383",
   "metadata": {},
   "source": [
    "#### Truncated BPTT\n",
    "時間軸方向に長くなり過ぎたネットワークを適当な場所で切り取ることで，小さなネットワークを（複数）作るというアイデア．そして，その切り取った小さなネットワークに対して，誤差逆伝播法を行う．\n",
    "\n",
    "#### データをシーケンシャルに与える\n",
    "順伝播のつながりを維持させながら，ブロック単位で誤差逆伝播法を適用する．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c96dc",
   "metadata": {},
   "source": [
    "### 5.2.5 Truncated BPTTのミニバッチ学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f21bc5",
   "metadata": {},
   "source": [
    "ミニバッチ学習を行う場合は，各バッチの開始位置をオフセットとしてずらして，シーケンシャルに与えていく．シーケンシャルにデータを与えていく途中で終端に達した場合は，先頭に戻すような対応が必要．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddb44c",
   "metadata": {},
   "source": [
    "## 5.3 RNNの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8f2f3",
   "metadata": {},
   "source": [
    "- RNNレイヤ：Time RNNレイヤ内の1ステップの処理を行うレイヤ\n",
    "- Time RNNレイヤ：Tステップ分の処理をまとめて行うレイヤ\n",
    "- <code>class RNN</code>：RNNの1ステップの処理を行うクラス\n",
    "- <code>class TimeRNN</code>：RNNクラスを利用して，Tステップの処理をまとめて行うクラス"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80fdbda",
   "metadata": {},
   "source": [
    "### 5.3.1 RNNレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad71405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# RNNクラス\n",
    "class RNN:\n",
    "    # 初期化，コンストラクタ\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh),\\\n",
    "                     np.zeros_like(b)]\n",
    "        self.chache = None\n",
    "        \n",
    "    # 順伝播\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.chache = (x, h_prev, h_text)\n",
    "        return h_next\n",
    "    \n",
    "    # 逆伝播\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.chache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next ** 2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.dot(h_prev.T, dt)\n",
    "        dh_prev = np.dot(dt, Wh.T)\n",
    "        dWx = np.dot(x.T, dt)\n",
    "        dx = np.dot(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh        \n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78429cf",
   "metadata": {},
   "source": [
    "### 5.3.2 Time RNNレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3146871",
   "metadata": {},
   "source": [
    "#### 隠れ状態h\n",
    "Time RNNクラスのメンバ変数に保持する．隠れ状態の引継ぎを行う際に使用する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe470c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time RNN\n",
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh),\n",
    "                     np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for i in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh)  # 合算した勾配\n",
    "            dxs[:, t, :] = dx\n",
    "            \n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c13a6",
   "metadata": {},
   "source": [
    "長い時系列データを処理するとき，RNNの隠れ状態を維持する必要がある．このような隠れ状態を維持する機能は，statefulという言葉でよく表される．多くのディープラーニングのフレームワークでは，RNNレイヤの引数にstatefulというものがあり，前時刻の隠れ状態を保持するかどうか指定することができる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a3835c",
   "metadata": {},
   "source": [
    "## 5.4 時系列データを扱うレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8b251",
   "metadata": {},
   "source": [
    "#### RNNLMの完成を目指す\n",
    "RNN Language Modelを作成する．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259a2dc",
   "metadata": {},
   "source": [
    "### 5.4.1 RNNLMの全体図"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0346d19",
   "metadata": {},
   "source": [
    "RNNLMはこれまで入力された単語を記憶し，それを元に次に出現する単語を予測する．これを可能にしているのがRNNレイヤの存在．RNNレイヤが過去から現在へとデータを継続して流すことによって，過去の情報をエンコードして記憶することを可能にしている．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea45762",
   "metadata": {},
   "source": [
    "### 5.4.2 Timeレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61012587",
   "metadata": {},
   "source": [
    "## 5.5 RNNLMの学習と評価"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461db27b",
   "metadata": {},
   "source": [
    "### 5.5.1 RNNLMの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933cd3ab",
   "metadata": {},
   "source": [
    "#### SimpleRnnlmクラス\n",
    "4つのTimeレイヤを重ねたニューラルネットワーク．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b9a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleRnnlm\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea9d53",
   "metadata": {},
   "source": [
    "### 5.5.2 言語モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6c43d",
   "metadata": {},
   "source": [
    "#### パープレキシティ\n",
    "言語モデルでは，過去の与えられた単語（情報）から次に出現する単語の確率分布を出力するが，このときに言語モデルの予測性能の良さを評価する指標．確率の逆数がそれに該当する．パープレキシティの値は小さければ小さい程良い．値を直観的に解釈するなら分岐数と考えると分かりやすい．\n",
    "\n",
    "#### パープレキシティの数式\n",
    "### $$\n",
    "L = -\\frac{1}{N}\\sum_{n}\\sum_{k}t_{nk}logy_{nk}\n",
    "$$\n",
    "$$\n",
    "perplexity = e^L\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72239840",
   "metadata": {},
   "source": [
    "情報理論の分野では，パープレキシティは「平均分岐数」とも呼ばれる．これは，データが1個のときに説明した「分岐数」をN個の場合で平均したものという解釈．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d646d3f",
   "metadata": {},
   "source": [
    "### 5.5.3 RNNLMの学習コード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aaa3f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 1000, vocabulary size: 418\n",
      "| epoch 1 | perplexity 394.52\n",
      "| epoch 2 | perplexity 274.94\n",
      "| epoch 3 | perplexity 226.20\n",
      "| epoch 4 | perplexity 216.44\n",
      "| epoch 5 | perplexity 206.20\n",
      "| epoch 6 | perplexity 203.45\n",
      "| epoch 7 | perplexity 200.09\n",
      "| epoch 8 | perplexity 196.90\n",
      "| epoch 9 | perplexity 191.31\n",
      "| epoch 10 | perplexity 192.36\n",
      "| epoch 11 | perplexity 187.80\n",
      "| epoch 12 | perplexity 191.65\n",
      "| epoch 13 | perplexity 189.31\n",
      "| epoch 14 | perplexity 190.27\n",
      "| epoch 15 | perplexity 188.82\n",
      "| epoch 16 | perplexity 185.41\n",
      "| epoch 17 | perplexity 183.38\n",
      "| epoch 18 | perplexity 179.26\n",
      "| epoch 19 | perplexity 180.24\n",
      "| epoch 20 | perplexity 181.45\n",
      "| epoch 21 | perplexity 179.00\n",
      "| epoch 22 | perplexity 174.53\n",
      "| epoch 23 | perplexity 171.50\n",
      "| epoch 24 | perplexity 173.54\n",
      "| epoch 25 | perplexity 171.29\n",
      "| epoch 26 | perplexity 169.70\n",
      "| epoch 27 | perplexity 164.24\n",
      "| epoch 28 | perplexity 162.68\n",
      "| epoch 29 | perplexity 158.91\n",
      "| epoch 30 | perplexity 153.10\n",
      "| epoch 31 | perplexity 154.13\n",
      "| epoch 32 | perplexity 147.04\n",
      "| epoch 33 | perplexity 147.96\n",
      "| epoch 34 | perplexity 140.56\n",
      "| epoch 35 | perplexity 139.31\n",
      "| epoch 36 | perplexity 132.74\n",
      "| epoch 37 | perplexity 131.66\n",
      "| epoch 38 | perplexity 125.28\n",
      "| epoch 39 | perplexity 120.15\n",
      "| epoch 40 | perplexity 114.21\n",
      "| epoch 41 | perplexity 113.91\n",
      "| epoch 42 | perplexity 107.34\n",
      "| epoch 43 | perplexity 101.78\n",
      "| epoch 44 | perplexity 98.89\n",
      "| epoch 45 | perplexity 93.61\n",
      "| epoch 46 | perplexity 92.00\n",
      "| epoch 47 | perplexity 86.79\n",
      "| epoch 48 | perplexity 81.61\n",
      "| epoch 49 | perplexity 79.79\n",
      "| epoch 50 | perplexity 75.15\n",
      "| epoch 51 | perplexity 72.08\n",
      "| epoch 52 | perplexity 69.23\n",
      "| epoch 53 | perplexity 64.48\n",
      "| epoch 54 | perplexity 62.59\n",
      "| epoch 55 | perplexity 59.31\n",
      "| epoch 56 | perplexity 57.20\n",
      "| epoch 57 | perplexity 53.18\n",
      "| epoch 58 | perplexity 51.07\n",
      "| epoch 59 | perplexity 48.13\n",
      "| epoch 60 | perplexity 44.98\n",
      "| epoch 61 | perplexity 44.40\n",
      "| epoch 62 | perplexity 41.16\n",
      "| epoch 63 | perplexity 37.50\n",
      "| epoch 64 | perplexity 36.67\n",
      "| epoch 65 | perplexity 35.16\n",
      "| epoch 66 | perplexity 33.41\n",
      "| epoch 67 | perplexity 31.55\n",
      "| epoch 68 | perplexity 29.52\n",
      "| epoch 69 | perplexity 29.07\n",
      "| epoch 70 | perplexity 27.11\n",
      "| epoch 71 | perplexity 25.78\n",
      "| epoch 72 | perplexity 24.61\n",
      "| epoch 73 | perplexity 23.13\n",
      "| epoch 74 | perplexity 21.63\n",
      "| epoch 75 | perplexity 21.09\n",
      "| epoch 76 | perplexity 19.59\n",
      "| epoch 77 | perplexity 17.97\n",
      "| epoch 78 | perplexity 17.13\n",
      "| epoch 79 | perplexity 15.99\n",
      "| epoch 80 | perplexity 15.51\n",
      "| epoch 81 | perplexity 14.60\n",
      "| epoch 82 | perplexity 14.39\n",
      "| epoch 83 | perplexity 13.31\n",
      "| epoch 84 | perplexity 13.46\n",
      "| epoch 85 | perplexity 12.15\n",
      "| epoch 86 | perplexity 11.83\n",
      "| epoch 87 | perplexity 10.48\n",
      "| epoch 88 | perplexity 10.40\n",
      "| epoch 89 | perplexity 9.41\n",
      "| epoch 90 | perplexity 9.21\n",
      "| epoch 91 | perplexity 8.88\n",
      "| epoch 92 | perplexity 8.38\n",
      "| epoch 93 | perplexity 8.03\n",
      "| epoch 94 | perplexity 7.29\n",
      "| epoch 95 | perplexity 7.00\n",
      "| epoch 96 | perplexity 7.03\n",
      "| epoch 97 | perplexity 6.95\n",
      "| epoch 98 | perplexity 6.55\n",
      "| epoch 99 | perplexity 6.16\n",
      "| epoch 100 | perplexity 5.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['IPAexGothic'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 5  # Truncated BPTTの展開する時間サイズ\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 学習データの読み込み（データセットを小さくする）\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 入力\n",
    "ts = corpus[1:]  # 出力（教師ラベル）\n",
    "data_size = len(xs)\n",
    "print('corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 学習時に使用する変数\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# モデルの生成\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# ミニバッチの各サンプルの読み込み開始位置を計算\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n",
    "\n",
    "# グラフの描画\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c33e4",
   "metadata": {},
   "source": [
    "### 5.5.4 RNNLMのTrainerクラス"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d14e3",
   "metadata": {},
   "source": [
    "## 5.6 まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c14faa",
   "metadata": {},
   "source": [
    "#### 本章で学んだこと\n",
    "- RNNはループする経路があり，それによって隠れ状態を内部に記憶することができる\n",
    "- RNNのループ経路を展開することで，複数のRNNレイヤがつながったネットワークと解釈することができ，通常の誤差逆伝播法によって学習することができる(=BPTT)\n",
    "- 長い時系列データを学習する場合は，適当な長さでデータのまとまりを作り，-これを「ブロック」という-,ブロック単位でBPTTによる学習を行う(=Trancated BPTT)\n",
    "- Truncated BPTTでは逆伝播のつながりのみを切断する\n",
    "- Trancated BPTTでは順伝播のつながりは維持するため，データはシーケンシャルに与える必要がある\n",
    "- 言語モデルは，単語の羅列を確率として解釈する\n",
    "- RNNレイヤを利用した条件付き言語モデルは，（理論的には）それまで登場した単語の情報を記憶することができる．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
