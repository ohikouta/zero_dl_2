{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf9c99f",
   "metadata": {},
   "source": [
    "# 3章 Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d1b0a",
   "metadata": {},
   "source": [
    "## 3.1 推論ベースの手法とニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d06bb9",
   "metadata": {},
   "source": [
    "### 3.1.1 カウントベースの手法の問題点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c5785",
   "metadata": {},
   "source": [
    "カウントベースの手法では大規模なコーパスを扱う場合に問題が発生する．計算量が多すぎてキャパオーバーになる．\n",
    "\n",
    "カウントベースが学習データを一度にまとめて処理するのに対して，推論ベースの手法は学習データの一部を使って逐次的に学習する．つまりデータを小分けにする．（ミニバッチで学習する）そしてニューラルネットワークの学習は複数マシン/複数GPUの利用による並列計算も可能なので，全体の学習も高速化できる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7467a2ea",
   "metadata": {},
   "source": [
    "### 3.1.2 推論ベースの手法の概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74fba2",
   "metadata": {},
   "source": [
    "コンテキストを入力としてモデル（ニューラルネットワーク）を通じて各単語の出現確率を出力する．この枠組みの中で正しい推測ができるように，コーパスを使ってモデルの学習を行う．\n",
    "\n",
    "その学習の結果として単語の分散表現を得られるというのが推論ベースの手法の全体図になる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74b253",
   "metadata": {},
   "source": [
    "### 3.1.3 ニューラルネットワークにおける単語の処理方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf2f825",
   "metadata": {},
   "source": [
    "ニューラルネットワークの中では単語をそのまま文字列としては扱えないので，one-hot表現を用いる．\n",
    "\n",
    "単語をベクトルで表現できるということはすなわち，そのベクトルはニューラルネットワークを構成するレイヤとして考えられることになる．\n",
    "\n",
    "ディープラーニングのフレームワークでは，全結合層の生成時にバイアスを用いないような選択ができる．今回はバイアスを省略．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "933b8c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.78712386  1.21221821  0.77690671]\n",
      " [-0.57255538  0.84700939 -0.53853318]\n",
      " [ 0.94835959  0.39010704 -0.05828024]\n",
      " [ 0.01839848  1.27450426 -0.57851938]\n",
      " [-1.22962531  0.83934524 -0.41959013]\n",
      " [ 1.45337477 -0.53299252 -0.67785329]\n",
      " [ 0.71606151 -0.57410542  1.48549478]]\n",
      "[[1.78712386 1.21221821 0.77690671]]\n"
     ]
    }
   ],
   "source": [
    "# ここまでの話をコードで実装\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]])  # 入力\n",
    "W = np.random.randn(7, 3)              # 重み\n",
    "print(W)\n",
    "h = np.dot(c, W)                       # 中間ノード\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b69f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.54428162 -0.23365602  0.52056395]]\n"
     ]
    }
   ],
   "source": [
    "# MatMulレイヤで同様の処理を実装\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "W = np.random.randn(7, 3)\n",
    "layer = MatMul(W)\n",
    "h = layer.forward(c)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54017d44",
   "metadata": {},
   "source": [
    "## 3.2 シンプルなword2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8eb14",
   "metadata": {},
   "source": [
    "ここからはword2vecの実装に取り掛かる．\n",
    "\n",
    "具体的には，ここまで見てきたモデルに取り入れるニューラルネットワークにword2vecで提案されているcontinuous bag-of-words(CBOW)と呼ばれるモデルを使う．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ef5a3",
   "metadata": {},
   "source": [
    "### 3.2.1 CBOWモデルの推論処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db92a2",
   "metadata": {},
   "source": [
    "#### CBOWモデル\n",
    "コンテキストからターゲットを推測することを目的としたニューラルネットワーク．入力はコンテキスト，コンテキストの数に応じて入力層の数は変化する．中間層にあるニューロンの値は各入力層全結合による変換後の値の平均値をとる．出力層のニューロンは各単語に対応している．出力層にニューロンは各単語のスコアであり，softmax関数を使用してそれを確率に変換する．全結合層に重み7×3の行列は，単語の分散表現であり，学習を重ねることで，コンテキストから出現する単語をうまく推測できるように，各単語の分散表現が更新される．\n",
    "\n",
    "- エンコード：人間には理解できないコード\n",
    "- デコード：エンコードされた情報を，人間が理解できる表現へに復元する作業\n",
    "\n",
    "#### レイヤ視点でCBOWモデルを考える\n",
    "最初に入力層の数だけMatMulレイヤがあり，それぞれを加算する．そして加算された値の平均を求めて中間層のニューロンとする．最後に中間層に対してもMatMulレイヤが適用されスコアを出力する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a113cdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.92983489 -0.35052161  0.15652616 -1.59789654 -0.66392563  0.04142847\n",
      "  -0.39454069]]\n"
     ]
    }
   ],
   "source": [
    "# CBOWモデルの推論処理を実装\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "# サンプルのコンテキストデータ\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
    "\n",
    "# 重みの初期化\n",
    "W_in = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "# レイヤの生成\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "# 順伝播\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b199fa1",
   "metadata": {},
   "source": [
    "### 3.2.2 CBOWモデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff49d3",
   "metadata": {},
   "source": [
    "CBOWモデルの学習で行うことは正しい予測ができるように重みを調整すること．単語の出現パターンを捉えたベクトルが学習される．\n",
    "\n",
    "CBOWモデルはコーパスにおける単語の出現パターンを学ぶだけなので，コーパスが違えば，学習で得られる単語の分散表現は異なる．\n",
    "\n",
    "学習はシンプルで，スコアをSoftmaxで確率に変換し，教師ラベルと比較して交差エントロピー誤差を求め，損失を出す．損失を用いて学習を行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3d335",
   "metadata": {},
   "source": [
    "### 3.2.3 word2vecの重みと分散表現"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103a7d7",
   "metadata": {},
   "source": [
    "word2vecで使用されるネットワークには2つの重みがある．入力側の重みの各行は単語の分散表現を表し，出力側の重みも同様に単語の意味がエンコードされた重みが格納されている．ただし出力側は各行ではなく，各列に単語の分散表現が格納されている．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd0e69",
   "metadata": {},
   "source": [
    "## 3.3 学習データの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09117375",
   "metadata": {},
   "source": [
    "### 3.3.1 コンテキストとターゲット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a0c409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
      "================================================================================\n",
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "# コーパスからコンテキストとターゲットを作成する\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "\n",
    "print(id_to_word)\n",
    "\n",
    "# ======================================================================\n",
    "print(\"=\"*80)\n",
    "def create_contexts_target(corpus, window_size=1):\n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "    \n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "    \n",
    "    return np.array(contexts), np.array(target)\n",
    "\n",
    "# ======================================================================\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "print(contexts)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5526ec",
   "metadata": {},
   "source": [
    "### 3.3.2 one-hot表現への変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9c1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンテキストとターゲットのone-hot変換を含めてここまでの処理を実装\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4079769",
   "metadata": {},
   "source": [
    "## 3.4 CBOWモデルの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "016cc5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークの実装\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "\n",
    "class SimpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        \n",
    "        # 重みの初期化\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "        \n",
    "        # レイヤの生成\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        # メンバ変数に単語の分散表現を設定\n",
    "        self.word_vecs = W_in\n",
    "    \n",
    "    # 順伝播\n",
    "    def forward(self, contexts, target):\n",
    "        h0 = self.in_layer0.forward(contexts[:, 0])\n",
    "        h1 = self.in_layer0.forward(contexts[:, 1])\n",
    "        h = (h0 + h1) * 0.5\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "        return loss\n",
    "    \n",
    "    # 逆伝播\n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer0.backward(da)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6af69",
   "metadata": {},
   "source": [
    "### 3.4.1 学習コードの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b49a9",
   "metadata": {},
   "source": [
    "CBOWモデルの学習は通常のニューラルネットワークの学習と全く同じ．まずは学習データを準備して，ニューラルネットワークに与える．そして勾配を求めて重みパラメータを逐次アップデートする．パラメータの更新を行う方法には，SGDやAdaGradなど有名な手法がいくつかあるが，Adamというアルゴリズムを今回は使用する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5eed340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 2 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 3 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 4 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 5 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 6 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 7 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 8 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 9 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 10 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 11 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 12 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 13 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 14 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 15 |  iter 1 / 6 | time 0[s] | loss 2.83\n",
      "| epoch 16 |  iter 1 / 6 | time 0[s] | loss 2.82\n",
      "| epoch 17 |  iter 1 / 6 | time 0[s] | loss 2.82\n",
      "| epoch 18 |  iter 1 / 6 | time 0[s] | loss 2.82\n",
      "| epoch 19 |  iter 1 / 6 | time 0[s] | loss 2.82\n",
      "| epoch 20 |  iter 1 / 6 | time 0[s] | loss 2.82\n",
      "| epoch 21 |  iter 1 / 6 | time 0[s] | loss 2.81\n",
      "| epoch 22 |  iter 1 / 6 | time 0[s] | loss 2.81\n",
      "| epoch 23 |  iter 1 / 6 | time 0[s] | loss 2.81\n",
      "| epoch 24 |  iter 1 / 6 | time 0[s] | loss 2.80\n",
      "| epoch 25 |  iter 1 / 6 | time 0[s] | loss 2.80\n",
      "| epoch 26 |  iter 1 / 6 | time 0[s] | loss 2.80\n",
      "| epoch 27 |  iter 1 / 6 | time 0[s] | loss 2.79\n",
      "| epoch 28 |  iter 1 / 6 | time 0[s] | loss 2.79\n",
      "| epoch 29 |  iter 1 / 6 | time 0[s] | loss 2.79\n",
      "| epoch 30 |  iter 1 / 6 | time 0[s] | loss 2.78\n",
      "| epoch 31 |  iter 1 / 6 | time 0[s] | loss 2.77\n",
      "| epoch 32 |  iter 1 / 6 | time 0[s] | loss 2.77\n",
      "| epoch 33 |  iter 1 / 6 | time 0[s] | loss 2.77\n",
      "| epoch 34 |  iter 1 / 6 | time 0[s] | loss 2.76\n",
      "| epoch 35 |  iter 1 / 6 | time 0[s] | loss 2.76\n",
      "| epoch 36 |  iter 1 / 6 | time 0[s] | loss 2.75\n",
      "| epoch 37 |  iter 1 / 6 | time 0[s] | loss 2.75\n",
      "| epoch 38 |  iter 1 / 6 | time 0[s] | loss 2.74\n",
      "| epoch 39 |  iter 1 / 6 | time 0[s] | loss 2.73\n",
      "| epoch 40 |  iter 1 / 6 | time 0[s] | loss 2.73\n",
      "| epoch 41 |  iter 1 / 6 | time 0[s] | loss 2.72\n",
      "| epoch 42 |  iter 1 / 6 | time 0[s] | loss 2.72\n",
      "| epoch 43 |  iter 1 / 6 | time 0[s] | loss 2.71\n",
      "| epoch 44 |  iter 1 / 6 | time 0[s] | loss 2.70\n",
      "| epoch 45 |  iter 1 / 6 | time 0[s] | loss 2.70\n",
      "| epoch 46 |  iter 1 / 6 | time 0[s] | loss 2.68\n",
      "| epoch 47 |  iter 1 / 6 | time 0[s] | loss 2.68\n",
      "| epoch 48 |  iter 1 / 6 | time 0[s] | loss 2.68\n",
      "| epoch 49 |  iter 1 / 6 | time 0[s] | loss 2.66\n",
      "| epoch 50 |  iter 1 / 6 | time 0[s] | loss 2.66\n",
      "| epoch 51 |  iter 1 / 6 | time 0[s] | loss 2.66\n",
      "| epoch 52 |  iter 1 / 6 | time 0[s] | loss 2.65\n",
      "| epoch 53 |  iter 1 / 6 | time 0[s] | loss 2.62\n",
      "| epoch 54 |  iter 1 / 6 | time 0[s] | loss 2.63\n",
      "| epoch 55 |  iter 1 / 6 | time 0[s] | loss 2.62\n",
      "| epoch 56 |  iter 1 / 6 | time 0[s] | loss 2.60\n",
      "| epoch 57 |  iter 1 / 6 | time 0[s] | loss 2.62\n",
      "| epoch 58 |  iter 1 / 6 | time 0[s] | loss 2.59\n",
      "| epoch 59 |  iter 1 / 6 | time 0[s] | loss 2.58\n",
      "| epoch 60 |  iter 1 / 6 | time 0[s] | loss 2.57\n",
      "| epoch 61 |  iter 1 / 6 | time 0[s] | loss 2.57\n",
      "| epoch 62 |  iter 1 / 6 | time 0[s] | loss 2.56\n",
      "| epoch 63 |  iter 1 / 6 | time 0[s] | loss 2.53\n",
      "| epoch 64 |  iter 1 / 6 | time 0[s] | loss 2.55\n",
      "| epoch 65 |  iter 1 / 6 | time 0[s] | loss 2.52\n",
      "| epoch 66 |  iter 1 / 6 | time 0[s] | loss 2.53\n",
      "| epoch 67 |  iter 1 / 6 | time 0[s] | loss 2.50\n",
      "| epoch 68 |  iter 1 / 6 | time 0[s] | loss 2.50\n",
      "| epoch 69 |  iter 1 / 6 | time 0[s] | loss 2.49\n",
      "| epoch 70 |  iter 1 / 6 | time 0[s] | loss 2.47\n",
      "| epoch 71 |  iter 1 / 6 | time 0[s] | loss 2.48\n",
      "| epoch 72 |  iter 1 / 6 | time 0[s] | loss 2.45\n",
      "| epoch 73 |  iter 1 / 6 | time 0[s] | loss 2.46\n",
      "| epoch 74 |  iter 1 / 6 | time 0[s] | loss 2.42\n",
      "| epoch 75 |  iter 1 / 6 | time 0[s] | loss 2.42\n",
      "| epoch 76 |  iter 1 / 6 | time 0[s] | loss 2.43\n",
      "| epoch 77 |  iter 1 / 6 | time 0[s] | loss 2.42\n",
      "| epoch 78 |  iter 1 / 6 | time 0[s] | loss 2.40\n",
      "| epoch 79 |  iter 1 / 6 | time 0[s] | loss 2.39\n",
      "| epoch 80 |  iter 1 / 6 | time 0[s] | loss 2.34\n",
      "| epoch 81 |  iter 1 / 6 | time 0[s] | loss 2.41\n",
      "| epoch 82 |  iter 1 / 6 | time 0[s] | loss 2.34\n",
      "| epoch 83 |  iter 1 / 6 | time 0[s] | loss 2.32\n",
      "| epoch 84 |  iter 1 / 6 | time 0[s] | loss 2.33\n",
      "| epoch 85 |  iter 1 / 6 | time 0[s] | loss 2.34\n",
      "| epoch 86 |  iter 1 / 6 | time 0[s] | loss 2.28\n",
      "| epoch 87 |  iter 1 / 6 | time 0[s] | loss 2.32\n",
      "| epoch 88 |  iter 1 / 6 | time 0[s] | loss 2.26\n",
      "| epoch 89 |  iter 1 / 6 | time 0[s] | loss 2.29\n",
      "| epoch 90 |  iter 1 / 6 | time 0[s] | loss 2.27\n",
      "| epoch 91 |  iter 1 / 6 | time 0[s] | loss 2.23\n",
      "| epoch 92 |  iter 1 / 6 | time 0[s] | loss 2.23\n",
      "| epoch 93 |  iter 1 / 6 | time 0[s] | loss 2.22\n",
      "| epoch 94 |  iter 1 / 6 | time 0[s] | loss 2.24\n",
      "| epoch 95 |  iter 1 / 6 | time 0[s] | loss 2.21\n",
      "| epoch 96 |  iter 1 / 6 | time 0[s] | loss 2.20\n",
      "| epoch 97 |  iter 1 / 6 | time 0[s] | loss 2.15\n",
      "| epoch 98 |  iter 1 / 6 | time 0[s] | loss 2.18\n",
      "| epoch 99 |  iter 1 / 6 | time 0[s] | loss 2.15\n",
      "| epoch 100 |  iter 1 / 6 | time 0[s] | loss 2.14\n",
      "| epoch 101 |  iter 1 / 6 | time 0[s] | loss 2.16\n",
      "| epoch 102 |  iter 1 / 6 | time 0[s] | loss 2.10\n",
      "| epoch 103 |  iter 1 / 6 | time 0[s] | loss 2.15\n",
      "| epoch 104 |  iter 1 / 6 | time 0[s] | loss 2.13\n",
      "| epoch 105 |  iter 1 / 6 | time 0[s] | loss 2.08\n",
      "| epoch 106 |  iter 1 / 6 | time 0[s] | loss 2.05\n",
      "| epoch 107 |  iter 1 / 6 | time 0[s] | loss 2.10\n",
      "| epoch 108 |  iter 1 / 6 | time 0[s] | loss 2.07\n",
      "| epoch 109 |  iter 1 / 6 | time 0[s] | loss 2.04\n",
      "| epoch 110 |  iter 1 / 6 | time 0[s] | loss 2.07\n",
      "| epoch 111 |  iter 1 / 6 | time 0[s] | loss 2.03\n",
      "| epoch 112 |  iter 1 / 6 | time 0[s] | loss 2.07\n",
      "| epoch 113 |  iter 1 / 6 | time 0[s] | loss 1.95\n",
      "| epoch 114 |  iter 1 / 6 | time 0[s] | loss 2.02\n",
      "| epoch 115 |  iter 1 / 6 | time 0[s] | loss 1.97\n",
      "| epoch 116 |  iter 1 / 6 | time 0[s] | loss 1.98\n",
      "| epoch 117 |  iter 1 / 6 | time 0[s] | loss 1.91\n",
      "| epoch 118 |  iter 1 / 6 | time 0[s] | loss 2.01\n",
      "| epoch 119 |  iter 1 / 6 | time 0[s] | loss 1.92\n",
      "| epoch 120 |  iter 1 / 6 | time 0[s] | loss 1.96\n",
      "| epoch 121 |  iter 1 / 6 | time 0[s] | loss 1.90\n",
      "| epoch 122 |  iter 1 / 6 | time 0[s] | loss 1.88\n",
      "| epoch 123 |  iter 1 / 6 | time 0[s] | loss 1.93\n",
      "| epoch 124 |  iter 1 / 6 | time 0[s] | loss 1.93\n",
      "| epoch 125 |  iter 1 / 6 | time 0[s] | loss 1.82\n",
      "| epoch 126 |  iter 1 / 6 | time 0[s] | loss 1.87\n",
      "| epoch 127 |  iter 1 / 6 | time 0[s] | loss 1.83\n",
      "| epoch 128 |  iter 1 / 6 | time 0[s] | loss 1.90\n",
      "| epoch 129 |  iter 1 / 6 | time 0[s] | loss 1.80\n",
      "| epoch 130 |  iter 1 / 6 | time 0[s] | loss 1.81\n",
      "| epoch 131 |  iter 1 / 6 | time 0[s] | loss 1.86\n",
      "| epoch 132 |  iter 1 / 6 | time 0[s] | loss 1.77\n",
      "| epoch 133 |  iter 1 / 6 | time 0[s] | loss 1.89\n",
      "| epoch 134 |  iter 1 / 6 | time 0[s] | loss 1.72\n",
      "| epoch 135 |  iter 1 / 6 | time 0[s] | loss 1.78\n",
      "| epoch 136 |  iter 1 / 6 | time 0[s] | loss 1.70\n",
      "| epoch 137 |  iter 1 / 6 | time 0[s] | loss 1.79\n",
      "| epoch 138 |  iter 1 / 6 | time 0[s] | loss 1.73\n",
      "| epoch 139 |  iter 1 / 6 | time 0[s] | loss 1.75\n",
      "| epoch 140 |  iter 1 / 6 | time 0[s] | loss 1.68\n",
      "| epoch 141 |  iter 1 / 6 | time 0[s] | loss 1.70\n",
      "| epoch 142 |  iter 1 / 6 | time 0[s] | loss 1.72\n",
      "| epoch 143 |  iter 1 / 6 | time 0[s] | loss 1.72\n",
      "| epoch 144 |  iter 1 / 6 | time 0[s] | loss 1.62\n",
      "| epoch 145 |  iter 1 / 6 | time 0[s] | loss 1.76\n",
      "| epoch 146 |  iter 1 / 6 | time 0[s] | loss 1.62\n",
      "| epoch 147 |  iter 1 / 6 | time 0[s] | loss 1.65\n",
      "| epoch 148 |  iter 1 / 6 | time 0[s] | loss 1.74\n",
      "| epoch 149 |  iter 1 / 6 | time 0[s] | loss 1.56\n",
      "| epoch 150 |  iter 1 / 6 | time 0[s] | loss 1.60\n",
      "| epoch 151 |  iter 1 / 6 | time 0[s] | loss 1.73\n",
      "| epoch 152 |  iter 1 / 6 | time 0[s] | loss 1.54\n",
      "| epoch 153 |  iter 1 / 6 | time 0[s] | loss 1.65\n",
      "| epoch 154 |  iter 1 / 6 | time 0[s] | loss 1.62\n",
      "| epoch 155 |  iter 1 / 6 | time 0[s] | loss 1.55\n",
      "| epoch 156 |  iter 1 / 6 | time 0[s] | loss 1.52\n",
      "| epoch 157 |  iter 1 / 6 | time 0[s] | loss 1.64\n",
      "| epoch 158 |  iter 1 / 6 | time 0[s] | loss 1.58\n",
      "| epoch 159 |  iter 1 / 6 | time 0[s] | loss 1.58\n",
      "| epoch 160 |  iter 1 / 6 | time 0[s] | loss 1.47\n",
      "| epoch 161 |  iter 1 / 6 | time 0[s] | loss 1.53\n",
      "| epoch 162 |  iter 1 / 6 | time 0[s] | loss 1.52\n",
      "| epoch 163 |  iter 1 / 6 | time 0[s] | loss 1.57\n",
      "| epoch 164 |  iter 1 / 6 | time 0[s] | loss 1.55\n",
      "| epoch 165 |  iter 1 / 6 | time 0[s] | loss 1.54\n",
      "| epoch 166 |  iter 1 / 6 | time 0[s] | loss 1.43\n",
      "| epoch 167 |  iter 1 / 6 | time 0[s] | loss 1.55\n",
      "| epoch 168 |  iter 1 / 6 | time 0[s] | loss 1.40\n",
      "| epoch 169 |  iter 1 / 6 | time 0[s] | loss 1.58\n",
      "| epoch 170 |  iter 1 / 6 | time 0[s] | loss 1.40\n",
      "| epoch 171 |  iter 1 / 6 | time 0[s] | loss 1.44\n",
      "| epoch 172 |  iter 1 / 6 | time 0[s] | loss 1.49\n",
      "| epoch 173 |  iter 1 / 6 | time 0[s] | loss 1.40\n",
      "| epoch 174 |  iter 1 / 6 | time 0[s] | loss 1.46\n",
      "| epoch 175 |  iter 1 / 6 | time 0[s] | loss 1.37\n",
      "| epoch 176 |  iter 1 / 6 | time 0[s] | loss 1.55\n",
      "| epoch 177 |  iter 1 / 6 | time 0[s] | loss 1.32\n",
      "| epoch 178 |  iter 1 / 6 | time 0[s] | loss 1.42\n",
      "| epoch 179 |  iter 1 / 6 | time 0[s] | loss 1.39\n",
      "| epoch 180 |  iter 1 / 6 | time 0[s] | loss 1.45\n",
      "| epoch 181 |  iter 1 / 6 | time 0[s] | loss 1.28\n",
      "| epoch 182 |  iter 1 / 6 | time 0[s] | loss 1.49\n",
      "| epoch 183 |  iter 1 / 6 | time 0[s] | loss 1.36\n",
      "| epoch 184 |  iter 1 / 6 | time 0[s] | loss 1.42\n",
      "| epoch 185 |  iter 1 / 6 | time 0[s] | loss 1.35\n",
      "| epoch 186 |  iter 1 / 6 | time 0[s] | loss 1.39\n",
      "| epoch 187 |  iter 1 / 6 | time 0[s] | loss 1.28\n",
      "| epoch 188 |  iter 1 / 6 | time 0[s] | loss 1.41\n",
      "| epoch 189 |  iter 1 / 6 | time 0[s] | loss 1.29\n",
      "| epoch 190 |  iter 1 / 6 | time 0[s] | loss 1.36\n",
      "| epoch 191 |  iter 1 / 6 | time 0[s] | loss 1.34\n",
      "| epoch 192 |  iter 1 / 6 | time 0[s] | loss 1.28\n",
      "| epoch 193 |  iter 1 / 6 | time 0[s] | loss 1.29\n",
      "| epoch 194 |  iter 1 / 6 | time 0[s] | loss 1.33\n",
      "| epoch 195 |  iter 1 / 6 | time 0[s] | loss 1.27\n",
      "| epoch 196 |  iter 1 / 6 | time 0[s] | loss 1.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 197 |  iter 1 / 6 | time 0[s] | loss 1.33\n",
      "| epoch 198 |  iter 1 / 6 | time 0[s] | loss 1.30\n",
      "| epoch 199 |  iter 1 / 6 | time 0[s] | loss 1.19\n",
      "| epoch 200 |  iter 1 / 6 | time 0[s] | loss 1.29\n",
      "| epoch 201 |  iter 1 / 6 | time 0[s] | loss 1.29\n",
      "| epoch 202 |  iter 1 / 6 | time 0[s] | loss 1.31\n",
      "| epoch 203 |  iter 1 / 6 | time 0[s] | loss 1.20\n",
      "| epoch 204 |  iter 1 / 6 | time 0[s] | loss 1.20\n",
      "| epoch 205 |  iter 1 / 6 | time 0[s] | loss 1.33\n",
      "| epoch 206 |  iter 1 / 6 | time 0[s] | loss 1.21\n",
      "| epoch 207 |  iter 1 / 6 | time 0[s] | loss 1.26\n",
      "| epoch 208 |  iter 1 / 6 | time 0[s] | loss 1.27\n",
      "| epoch 209 |  iter 1 / 6 | time 0[s] | loss 1.13\n",
      "| epoch 210 |  iter 1 / 6 | time 0[s] | loss 1.29\n",
      "| epoch 211 |  iter 1 / 6 | time 0[s] | loss 1.26\n",
      "| epoch 212 |  iter 1 / 6 | time 0[s] | loss 1.11\n",
      "| epoch 213 |  iter 1 / 6 | time 0[s] | loss 1.24\n",
      "| epoch 214 |  iter 1 / 6 | time 0[s] | loss 1.21\n",
      "| epoch 215 |  iter 1 / 6 | time 0[s] | loss 1.14\n",
      "| epoch 216 |  iter 1 / 6 | time 0[s] | loss 1.28\n",
      "| epoch 217 |  iter 1 / 6 | time 0[s] | loss 1.15\n",
      "| epoch 218 |  iter 1 / 6 | time 0[s] | loss 1.19\n",
      "| epoch 219 |  iter 1 / 6 | time 0[s] | loss 1.09\n",
      "| epoch 220 |  iter 1 / 6 | time 0[s] | loss 1.26\n",
      "| epoch 221 |  iter 1 / 6 | time 0[s] | loss 1.17\n",
      "| epoch 222 |  iter 1 / 6 | time 0[s] | loss 1.17\n",
      "| epoch 223 |  iter 1 / 6 | time 0[s] | loss 1.09\n",
      "| epoch 224 |  iter 1 / 6 | time 0[s] | loss 1.13\n",
      "| epoch 225 |  iter 1 / 6 | time 0[s] | loss 1.16\n",
      "| epoch 226 |  iter 1 / 6 | time 0[s] | loss 1.20\n",
      "| epoch 227 |  iter 1 / 6 | time 0[s] | loss 0.96\n",
      "| epoch 228 |  iter 1 / 6 | time 0[s] | loss 1.15\n",
      "| epoch 229 |  iter 1 / 6 | time 0[s] | loss 1.13\n",
      "| epoch 230 |  iter 1 / 6 | time 0[s] | loss 1.18\n",
      "| epoch 231 |  iter 1 / 6 | time 0[s] | loss 1.13\n",
      "| epoch 232 |  iter 1 / 6 | time 0[s] | loss 1.19\n",
      "| epoch 233 |  iter 1 / 6 | time 0[s] | loss 1.16\n",
      "| epoch 234 |  iter 1 / 6 | time 0[s] | loss 1.12\n",
      "| epoch 235 |  iter 1 / 6 | time 0[s] | loss 1.08\n",
      "| epoch 236 |  iter 1 / 6 | time 0[s] | loss 1.05\n",
      "| epoch 237 |  iter 1 / 6 | time 0[s] | loss 1.16\n",
      "| epoch 238 |  iter 1 / 6 | time 0[s] | loss 0.92\n",
      "| epoch 239 |  iter 1 / 6 | time 0[s] | loss 1.13\n",
      "| epoch 240 |  iter 1 / 6 | time 0[s] | loss 1.21\n",
      "| epoch 241 |  iter 1 / 6 | time 0[s] | loss 1.08\n",
      "| epoch 242 |  iter 1 / 6 | time 0[s] | loss 1.11\n",
      "| epoch 243 |  iter 1 / 6 | time 0[s] | loss 1.01\n",
      "| epoch 244 |  iter 1 / 6 | time 0[s] | loss 1.10\n",
      "| epoch 245 |  iter 1 / 6 | time 0[s] | loss 1.08\n",
      "| epoch 246 |  iter 1 / 6 | time 0[s] | loss 1.11\n",
      "| epoch 247 |  iter 1 / 6 | time 0[s] | loss 1.01\n",
      "| epoch 248 |  iter 1 / 6 | time 0[s] | loss 1.18\n",
      "| epoch 249 |  iter 1 / 6 | time 0[s] | loss 0.94\n",
      "| epoch 250 |  iter 1 / 6 | time 0[s] | loss 1.13\n",
      "| epoch 251 |  iter 1 / 6 | time 0[s] | loss 1.02\n",
      "| epoch 252 |  iter 1 / 6 | time 0[s] | loss 1.02\n",
      "| epoch 253 |  iter 1 / 6 | time 0[s] | loss 1.07\n",
      "| epoch 254 |  iter 1 / 6 | time 0[s] | loss 1.09\n",
      "| epoch 255 |  iter 1 / 6 | time 0[s] | loss 0.98\n",
      "| epoch 256 |  iter 1 / 6 | time 0[s] | loss 1.04\n",
      "| epoch 257 |  iter 1 / 6 | time 0[s] | loss 1.03\n",
      "| epoch 258 |  iter 1 / 6 | time 0[s] | loss 1.01\n",
      "| epoch 259 |  iter 1 / 6 | time 0[s] | loss 1.11\n",
      "| epoch 260 |  iter 1 / 6 | time 0[s] | loss 0.88\n",
      "| epoch 261 |  iter 1 / 6 | time 0[s] | loss 1.02\n",
      "| epoch 262 |  iter 1 / 6 | time 0[s] | loss 1.01\n",
      "| epoch 263 |  iter 1 / 6 | time 0[s] | loss 1.00\n",
      "| epoch 264 |  iter 1 / 6 | time 0[s] | loss 1.06\n",
      "| epoch 265 |  iter 1 / 6 | time 0[s] | loss 1.04\n",
      "| epoch 266 |  iter 1 / 6 | time 0[s] | loss 0.91\n",
      "| epoch 267 |  iter 1 / 6 | time 0[s] | loss 1.04\n",
      "| epoch 268 |  iter 1 / 6 | time 0[s] | loss 0.95\n",
      "| epoch 269 |  iter 1 / 6 | time 0[s] | loss 1.07\n",
      "| epoch 270 |  iter 1 / 6 | time 0[s] | loss 0.91\n",
      "| epoch 271 |  iter 1 / 6 | time 0[s] | loss 1.03\n",
      "| epoch 272 |  iter 1 / 6 | time 0[s] | loss 0.93\n",
      "| epoch 273 |  iter 1 / 6 | time 0[s] | loss 1.00\n",
      "| epoch 274 |  iter 1 / 6 | time 0[s] | loss 1.01\n",
      "| epoch 275 |  iter 1 / 6 | time 0[s] | loss 0.97\n",
      "| epoch 276 |  iter 1 / 6 | time 0[s] | loss 0.92\n",
      "| epoch 277 |  iter 1 / 6 | time 0[s] | loss 0.94\n",
      "| epoch 278 |  iter 1 / 6 | time 0[s] | loss 0.98\n",
      "| epoch 279 |  iter 1 / 6 | time 0[s] | loss 1.09\n",
      "| epoch 280 |  iter 1 / 6 | time 0[s] | loss 0.91\n",
      "| epoch 281 |  iter 1 / 6 | time 0[s] | loss 1.00\n",
      "| epoch 282 |  iter 1 / 6 | time 0[s] | loss 0.95\n",
      "| epoch 283 |  iter 1 / 6 | time 0[s] | loss 0.92\n",
      "| epoch 284 |  iter 1 / 6 | time 0[s] | loss 0.91\n",
      "| epoch 285 |  iter 1 / 6 | time 0[s] | loss 0.94\n",
      "| epoch 286 |  iter 1 / 6 | time 0[s] | loss 1.02\n",
      "| epoch 287 |  iter 1 / 6 | time 0[s] | loss 0.92\n",
      "| epoch 288 |  iter 1 / 6 | time 0[s] | loss 0.80\n",
      "| epoch 289 |  iter 1 / 6 | time 0[s] | loss 1.05\n",
      "| epoch 290 |  iter 1 / 6 | time 0[s] | loss 0.89\n",
      "| epoch 291 |  iter 1 / 6 | time 0[s] | loss 0.85\n",
      "| epoch 292 |  iter 1 / 6 | time 0[s] | loss 0.98\n",
      "| epoch 293 |  iter 1 / 6 | time 0[s] | loss 0.93\n",
      "| epoch 294 |  iter 1 / 6 | time 0[s] | loss 0.99\n",
      "| epoch 295 |  iter 1 / 6 | time 0[s] | loss 0.78\n",
      "| epoch 296 |  iter 1 / 6 | time 0[s] | loss 0.92\n",
      "| epoch 297 |  iter 1 / 6 | time 0[s] | loss 0.93\n",
      "| epoch 298 |  iter 1 / 6 | time 0[s] | loss 0.84\n",
      "| epoch 299 |  iter 1 / 6 | time 0[s] | loss 0.94\n",
      "| epoch 300 |  iter 1 / 6 | time 0[s] | loss 0.73\n",
      "| epoch 301 |  iter 1 / 6 | time 0[s] | loss 0.89\n",
      "| epoch 302 |  iter 1 / 6 | time 0[s] | loss 0.96\n",
      "| epoch 303 |  iter 1 / 6 | time 0[s] | loss 0.90\n",
      "| epoch 304 |  iter 1 / 6 | time 0[s] | loss 0.89\n",
      "| epoch 305 |  iter 1 / 6 | time 0[s] | loss 0.97\n",
      "| epoch 306 |  iter 1 / 6 | time 0[s] | loss 0.81\n",
      "| epoch 307 |  iter 1 / 6 | time 0[s] | loss 0.93\n",
      "| epoch 308 |  iter 1 / 6 | time 0[s] | loss 0.87\n",
      "| epoch 309 |  iter 1 / 6 | time 0[s] | loss 0.82\n",
      "| epoch 310 |  iter 1 / 6 | time 0[s] | loss 0.90\n",
      "| epoch 311 |  iter 1 / 6 | time 0[s] | loss 0.93\n",
      "| epoch 312 |  iter 1 / 6 | time 0[s] | loss 0.84\n",
      "| epoch 313 |  iter 1 / 6 | time 0[s] | loss 0.85\n",
      "| epoch 314 |  iter 1 / 6 | time 0[s] | loss 0.86\n",
      "| epoch 315 |  iter 1 / 6 | time 0[s] | loss 0.85\n",
      "| epoch 316 |  iter 1 / 6 | time 0[s] | loss 0.84\n",
      "| epoch 317 |  iter 1 / 6 | time 0[s] | loss 0.91\n",
      "| epoch 318 |  iter 1 / 6 | time 0[s] | loss 0.85\n",
      "| epoch 319 |  iter 1 / 6 | time 0[s] | loss 0.79\n",
      "| epoch 320 |  iter 1 / 6 | time 0[s] | loss 0.89\n",
      "| epoch 321 |  iter 1 / 6 | time 0[s] | loss 0.82\n",
      "| epoch 322 |  iter 1 / 6 | time 0[s] | loss 0.96\n",
      "| epoch 323 |  iter 1 / 6 | time 0[s] | loss 0.89\n",
      "| epoch 324 |  iter 1 / 6 | time 0[s] | loss 0.70\n",
      "| epoch 325 |  iter 1 / 6 | time 0[s] | loss 0.91\n",
      "| epoch 326 |  iter 1 / 6 | time 0[s] | loss 0.80\n",
      "| epoch 327 |  iter 1 / 6 | time 0[s] | loss 0.76\n",
      "| epoch 328 |  iter 1 / 6 | time 0[s] | loss 0.81\n",
      "| epoch 329 |  iter 1 / 6 | time 0[s] | loss 0.77\n",
      "| epoch 330 |  iter 1 / 6 | time 0[s] | loss 0.91\n",
      "| epoch 331 |  iter 1 / 6 | time 0[s] | loss 0.82\n",
      "| epoch 332 |  iter 1 / 6 | time 0[s] | loss 0.80\n",
      "| epoch 333 |  iter 1 / 6 | time 0[s] | loss 0.90\n",
      "| epoch 334 |  iter 1 / 6 | time 0[s] | loss 0.72\n",
      "| epoch 335 |  iter 1 / 6 | time 0[s] | loss 0.91\n",
      "| epoch 336 |  iter 1 / 6 | time 0[s] | loss 0.71\n",
      "| epoch 337 |  iter 1 / 6 | time 0[s] | loss 0.81\n",
      "| epoch 338 |  iter 1 / 6 | time 0[s] | loss 0.84\n",
      "| epoch 339 |  iter 1 / 6 | time 0[s] | loss 0.76\n",
      "| epoch 340 |  iter 1 / 6 | time 0[s] | loss 0.86\n",
      "| epoch 341 |  iter 1 / 6 | time 0[s] | loss 0.84\n",
      "| epoch 342 |  iter 1 / 6 | time 0[s] | loss 0.82\n",
      "| epoch 343 |  iter 1 / 6 | time 0[s] | loss 0.77\n",
      "| epoch 344 |  iter 1 / 6 | time 0[s] | loss 0.82\n",
      "| epoch 345 |  iter 1 / 6 | time 0[s] | loss 0.70\n",
      "| epoch 346 |  iter 1 / 6 | time 0[s] | loss 0.82\n",
      "| epoch 347 |  iter 1 / 6 | time 0[s] | loss 0.86\n",
      "| epoch 348 |  iter 1 / 6 | time 0[s] | loss 0.70\n",
      "| epoch 349 |  iter 1 / 6 | time 0[s] | loss 0.73\n",
      "| epoch 350 |  iter 1 / 6 | time 0[s] | loss 0.87\n",
      "| epoch 351 |  iter 1 / 6 | time 0[s] | loss 0.74\n",
      "| epoch 352 |  iter 1 / 6 | time 0[s] | loss 0.74\n",
      "| epoch 353 |  iter 1 / 6 | time 0[s] | loss 0.83\n",
      "| epoch 354 |  iter 1 / 6 | time 1[s] | loss 0.89\n",
      "| epoch 355 |  iter 1 / 6 | time 1[s] | loss 0.75\n",
      "| epoch 356 |  iter 1 / 6 | time 1[s] | loss 0.76\n",
      "| epoch 357 |  iter 1 / 6 | time 1[s] | loss 0.81\n",
      "| epoch 358 |  iter 1 / 6 | time 1[s] | loss 0.71\n",
      "| epoch 359 |  iter 1 / 6 | time 1[s] | loss 0.81\n",
      "| epoch 360 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 361 |  iter 1 / 6 | time 1[s] | loss 0.82\n",
      "| epoch 362 |  iter 1 / 6 | time 1[s] | loss 0.72\n",
      "| epoch 363 |  iter 1 / 6 | time 1[s] | loss 0.84\n",
      "| epoch 364 |  iter 1 / 6 | time 1[s] | loss 0.81\n",
      "| epoch 365 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 366 |  iter 1 / 6 | time 1[s] | loss 0.73\n",
      "| epoch 367 |  iter 1 / 6 | time 1[s] | loss 0.75\n",
      "| epoch 368 |  iter 1 / 6 | time 1[s] | loss 0.72\n",
      "| epoch 369 |  iter 1 / 6 | time 1[s] | loss 0.74\n",
      "| epoch 370 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 371 |  iter 1 / 6 | time 1[s] | loss 0.73\n",
      "| epoch 372 |  iter 1 / 6 | time 1[s] | loss 0.82\n",
      "| epoch 373 |  iter 1 / 6 | time 1[s] | loss 0.74\n",
      "| epoch 374 |  iter 1 / 6 | time 1[s] | loss 0.72\n",
      "| epoch 375 |  iter 1 / 6 | time 1[s] | loss 0.74\n",
      "| epoch 376 |  iter 1 / 6 | time 1[s] | loss 0.78\n",
      "| epoch 377 |  iter 1 / 6 | time 1[s] | loss 0.72\n",
      "| epoch 378 |  iter 1 / 6 | time 1[s] | loss 0.70\n",
      "| epoch 379 |  iter 1 / 6 | time 1[s] | loss 0.79\n",
      "| epoch 380 |  iter 1 / 6 | time 1[s] | loss 0.71\n",
      "| epoch 381 |  iter 1 / 6 | time 1[s] | loss 0.70\n",
      "| epoch 382 |  iter 1 / 6 | time 1[s] | loss 0.80\n",
      "| epoch 383 |  iter 1 / 6 | time 1[s] | loss 0.65\n",
      "| epoch 384 |  iter 1 / 6 | time 1[s] | loss 0.76\n",
      "| epoch 385 |  iter 1 / 6 | time 1[s] | loss 0.74\n",
      "| epoch 386 |  iter 1 / 6 | time 1[s] | loss 0.73\n",
      "| epoch 387 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 388 |  iter 1 / 6 | time 1[s] | loss 0.78\n",
      "| epoch 389 |  iter 1 / 6 | time 1[s] | loss 0.65\n",
      "| epoch 390 |  iter 1 / 6 | time 1[s] | loss 0.70\n",
      "| epoch 391 |  iter 1 / 6 | time 1[s] | loss 0.74\n",
      "| epoch 392 |  iter 1 / 6 | time 1[s] | loss 0.72\n",
      "| epoch 393 |  iter 1 / 6 | time 1[s] | loss 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 394 |  iter 1 / 6 | time 1[s] | loss 0.64\n",
      "| epoch 395 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 396 |  iter 1 / 6 | time 1[s] | loss 0.77\n",
      "| epoch 397 |  iter 1 / 6 | time 1[s] | loss 0.66\n",
      "| epoch 398 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 399 |  iter 1 / 6 | time 1[s] | loss 0.68\n",
      "| epoch 400 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 401 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 402 |  iter 1 / 6 | time 1[s] | loss 0.68\n",
      "| epoch 403 |  iter 1 / 6 | time 1[s] | loss 0.77\n",
      "| epoch 404 |  iter 1 / 6 | time 1[s] | loss 0.78\n",
      "| epoch 405 |  iter 1 / 6 | time 1[s] | loss 0.65\n",
      "| epoch 406 |  iter 1 / 6 | time 1[s] | loss 0.64\n",
      "| epoch 407 |  iter 1 / 6 | time 1[s] | loss 0.72\n",
      "| epoch 408 |  iter 1 / 6 | time 1[s] | loss 0.65\n",
      "| epoch 409 |  iter 1 / 6 | time 1[s] | loss 0.70\n",
      "| epoch 410 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 411 |  iter 1 / 6 | time 1[s] | loss 0.75\n",
      "| epoch 412 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 413 |  iter 1 / 6 | time 1[s] | loss 0.72\n",
      "| epoch 414 |  iter 1 / 6 | time 1[s] | loss 0.70\n",
      "| epoch 415 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 416 |  iter 1 / 6 | time 1[s] | loss 0.66\n",
      "| epoch 417 |  iter 1 / 6 | time 1[s] | loss 0.73\n",
      "| epoch 418 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 419 |  iter 1 / 6 | time 1[s] | loss 0.62\n",
      "| epoch 420 |  iter 1 / 6 | time 1[s] | loss 0.75\n",
      "| epoch 421 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 422 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 423 |  iter 1 / 6 | time 1[s] | loss 0.53\n",
      "| epoch 424 |  iter 1 / 6 | time 1[s] | loss 0.73\n",
      "| epoch 425 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 426 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 427 |  iter 1 / 6 | time 1[s] | loss 0.68\n",
      "| epoch 428 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 429 |  iter 1 / 6 | time 1[s] | loss 0.66\n",
      "| epoch 430 |  iter 1 / 6 | time 1[s] | loss 0.74\n",
      "| epoch 431 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 432 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 433 |  iter 1 / 6 | time 1[s] | loss 0.70\n",
      "| epoch 434 |  iter 1 / 6 | time 1[s] | loss 0.56\n",
      "| epoch 435 |  iter 1 / 6 | time 1[s] | loss 0.75\n",
      "| epoch 436 |  iter 1 / 6 | time 1[s] | loss 0.61\n",
      "| epoch 437 |  iter 1 / 6 | time 1[s] | loss 0.53\n",
      "| epoch 438 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 439 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 440 |  iter 1 / 6 | time 1[s] | loss 0.65\n",
      "| epoch 441 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 442 |  iter 1 / 6 | time 1[s] | loss 0.56\n",
      "| epoch 443 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 444 |  iter 1 / 6 | time 1[s] | loss 0.62\n",
      "| epoch 445 |  iter 1 / 6 | time 1[s] | loss 0.61\n",
      "| epoch 446 |  iter 1 / 6 | time 1[s] | loss 0.56\n",
      "| epoch 447 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 448 |  iter 1 / 6 | time 1[s] | loss 0.61\n",
      "| epoch 449 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 450 |  iter 1 / 6 | time 1[s] | loss 0.60\n",
      "| epoch 451 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 452 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 453 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 454 |  iter 1 / 6 | time 1[s] | loss 0.67\n",
      "| epoch 455 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 456 |  iter 1 / 6 | time 1[s] | loss 0.60\n",
      "| epoch 457 |  iter 1 / 6 | time 1[s] | loss 0.65\n",
      "| epoch 458 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 459 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 460 |  iter 1 / 6 | time 1[s] | loss 0.59\n",
      "| epoch 461 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 462 |  iter 1 / 6 | time 1[s] | loss 0.65\n",
      "| epoch 463 |  iter 1 / 6 | time 1[s] | loss 0.52\n",
      "| epoch 464 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 465 |  iter 1 / 6 | time 1[s] | loss 0.61\n",
      "| epoch 466 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 467 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 468 |  iter 1 / 6 | time 1[s] | loss 0.59\n",
      "| epoch 469 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 470 |  iter 1 / 6 | time 1[s] | loss 0.74\n",
      "| epoch 471 |  iter 1 / 6 | time 1[s] | loss 0.59\n",
      "| epoch 472 |  iter 1 / 6 | time 1[s] | loss 0.51\n",
      "| epoch 473 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 474 |  iter 1 / 6 | time 1[s] | loss 0.56\n",
      "| epoch 475 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 476 |  iter 1 / 6 | time 1[s] | loss 0.64\n",
      "| epoch 477 |  iter 1 / 6 | time 1[s] | loss 0.59\n",
      "| epoch 478 |  iter 1 / 6 | time 1[s] | loss 0.56\n",
      "| epoch 479 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 480 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 481 |  iter 1 / 6 | time 1[s] | loss 0.61\n",
      "| epoch 482 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 483 |  iter 1 / 6 | time 1[s] | loss 0.53\n",
      "| epoch 484 |  iter 1 / 6 | time 1[s] | loss 0.68\n",
      "| epoch 485 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 486 |  iter 1 / 6 | time 1[s] | loss 0.65\n",
      "| epoch 487 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 488 |  iter 1 / 6 | time 1[s] | loss 0.64\n",
      "| epoch 489 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 490 |  iter 1 / 6 | time 1[s] | loss 0.69\n",
      "| epoch 491 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 492 |  iter 1 / 6 | time 1[s] | loss 0.52\n",
      "| epoch 493 |  iter 1 / 6 | time 1[s] | loss 0.65\n",
      "| epoch 494 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 495 |  iter 1 / 6 | time 1[s] | loss 0.62\n",
      "| epoch 496 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 497 |  iter 1 / 6 | time 1[s] | loss 0.60\n",
      "| epoch 498 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 499 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 500 |  iter 1 / 6 | time 1[s] | loss 0.62\n",
      "| epoch 501 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 502 |  iter 1 / 6 | time 1[s] | loss 0.48\n",
      "| epoch 503 |  iter 1 / 6 | time 1[s] | loss 0.54\n",
      "| epoch 504 |  iter 1 / 6 | time 1[s] | loss 0.62\n",
      "| epoch 505 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 506 |  iter 1 / 6 | time 1[s] | loss 0.59\n",
      "| epoch 507 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 508 |  iter 1 / 6 | time 1[s] | loss 0.60\n",
      "| epoch 509 |  iter 1 / 6 | time 1[s] | loss 0.52\n",
      "| epoch 510 |  iter 1 / 6 | time 1[s] | loss 0.64\n",
      "| epoch 511 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 512 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 513 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 514 |  iter 1 / 6 | time 1[s] | loss 0.53\n",
      "| epoch 515 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 516 |  iter 1 / 6 | time 1[s] | loss 0.68\n",
      "| epoch 517 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 518 |  iter 1 / 6 | time 1[s] | loss 0.63\n",
      "| epoch 519 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 520 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 521 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 522 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 523 |  iter 1 / 6 | time 1[s] | loss 0.50\n",
      "| epoch 524 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 525 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 526 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 527 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 528 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 529 |  iter 1 / 6 | time 1[s] | loss 0.52\n",
      "| epoch 530 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 531 |  iter 1 / 6 | time 1[s] | loss 0.50\n",
      "| epoch 532 |  iter 1 / 6 | time 1[s] | loss 0.50\n",
      "| epoch 533 |  iter 1 / 6 | time 1[s] | loss 0.64\n",
      "| epoch 534 |  iter 1 / 6 | time 1[s] | loss 0.60\n",
      "| epoch 535 |  iter 1 / 6 | time 1[s] | loss 0.33\n",
      "| epoch 536 |  iter 1 / 6 | time 1[s] | loss 0.60\n",
      "| epoch 537 |  iter 1 / 6 | time 1[s] | loss 0.54\n",
      "| epoch 538 |  iter 1 / 6 | time 1[s] | loss 0.48\n",
      "| epoch 539 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 540 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 541 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 542 |  iter 1 / 6 | time 1[s] | loss 0.56\n",
      "| epoch 543 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 544 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 545 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 546 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 547 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 548 |  iter 1 / 6 | time 1[s] | loss 0.61\n",
      "| epoch 549 |  iter 1 / 6 | time 1[s] | loss 0.54\n",
      "| epoch 550 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 551 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 552 |  iter 1 / 6 | time 1[s] | loss 0.48\n",
      "| epoch 553 |  iter 1 / 6 | time 1[s] | loss 0.51\n",
      "| epoch 554 |  iter 1 / 6 | time 1[s] | loss 0.51\n",
      "| epoch 555 |  iter 1 / 6 | time 1[s] | loss 0.54\n",
      "| epoch 556 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 557 |  iter 1 / 6 | time 1[s] | loss 0.52\n",
      "| epoch 558 |  iter 1 / 6 | time 1[s] | loss 0.48\n",
      "| epoch 559 |  iter 1 / 6 | time 1[s] | loss 0.53\n",
      "| epoch 560 |  iter 1 / 6 | time 1[s] | loss 0.56\n",
      "| epoch 561 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 562 |  iter 1 / 6 | time 1[s] | loss 0.50\n",
      "| epoch 563 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 564 |  iter 1 / 6 | time 1[s] | loss 0.53\n",
      "| epoch 565 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 566 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 567 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 568 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 569 |  iter 1 / 6 | time 1[s] | loss 0.58\n",
      "| epoch 570 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 571 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 572 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 573 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 574 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 575 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 576 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 577 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 578 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 579 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 580 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 581 |  iter 1 / 6 | time 1[s] | loss 0.54\n",
      "| epoch 582 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 583 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 584 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 585 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 586 |  iter 1 / 6 | time 1[s] | loss 0.52\n",
      "| epoch 587 |  iter 1 / 6 | time 1[s] | loss 0.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 588 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 589 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 590 |  iter 1 / 6 | time 1[s] | loss 0.51\n",
      "| epoch 591 |  iter 1 / 6 | time 1[s] | loss 0.48\n",
      "| epoch 592 |  iter 1 / 6 | time 1[s] | loss 0.53\n",
      "| epoch 593 |  iter 1 / 6 | time 1[s] | loss 0.35\n",
      "| epoch 594 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 595 |  iter 1 / 6 | time 1[s] | loss 0.48\n",
      "| epoch 596 |  iter 1 / 6 | time 1[s] | loss 0.56\n",
      "| epoch 597 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 598 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 599 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 600 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 601 |  iter 1 / 6 | time 1[s] | loss 0.50\n",
      "| epoch 602 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 603 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 604 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 605 |  iter 1 / 6 | time 1[s] | loss 0.52\n",
      "| epoch 606 |  iter 1 / 6 | time 1[s] | loss 0.48\n",
      "| epoch 607 |  iter 1 / 6 | time 1[s] | loss 0.35\n",
      "| epoch 608 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 609 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 610 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 611 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 612 |  iter 1 / 6 | time 1[s] | loss 0.57\n",
      "| epoch 613 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 614 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 615 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 616 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 617 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 618 |  iter 1 / 6 | time 1[s] | loss 0.55\n",
      "| epoch 619 |  iter 1 / 6 | time 1[s] | loss 0.35\n",
      "| epoch 620 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 621 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 622 |  iter 1 / 6 | time 1[s] | loss 0.50\n",
      "| epoch 623 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 624 |  iter 1 / 6 | time 1[s] | loss 0.51\n",
      "| epoch 625 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 626 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 627 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 628 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 629 |  iter 1 / 6 | time 1[s] | loss 0.56\n",
      "| epoch 630 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 631 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 632 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 633 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 634 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 635 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 636 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 637 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 638 |  iter 1 / 6 | time 1[s] | loss 0.51\n",
      "| epoch 639 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 640 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 641 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 642 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 643 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 644 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 645 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 646 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 647 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 648 |  iter 1 / 6 | time 1[s] | loss 0.52\n",
      "| epoch 649 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 650 |  iter 1 / 6 | time 1[s] | loss 0.35\n",
      "| epoch 651 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 652 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 653 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 654 |  iter 1 / 6 | time 1[s] | loss 0.53\n",
      "| epoch 655 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 656 |  iter 1 / 6 | time 1[s] | loss 0.52\n",
      "| epoch 657 |  iter 1 / 6 | time 1[s] | loss 0.28\n",
      "| epoch 658 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 659 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 660 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 661 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 662 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 663 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 664 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 665 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 666 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 667 |  iter 1 / 6 | time 1[s] | loss 0.54\n",
      "| epoch 668 |  iter 1 / 6 | time 1[s] | loss 0.34\n",
      "| epoch 669 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 670 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 671 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 672 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 673 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 674 |  iter 1 / 6 | time 1[s] | loss 0.34\n",
      "| epoch 675 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 676 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 677 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 678 |  iter 1 / 6 | time 1[s] | loss 0.48\n",
      "| epoch 679 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 680 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 681 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 682 |  iter 1 / 6 | time 1[s] | loss 0.35\n",
      "| epoch 683 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 684 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 685 |  iter 1 / 6 | time 1[s] | loss 0.44\n",
      "| epoch 686 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 687 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 688 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 689 |  iter 1 / 6 | time 1[s] | loss 0.38\n",
      "| epoch 690 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 691 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 692 |  iter 1 / 6 | time 1[s] | loss 0.38\n",
      "| epoch 693 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 694 |  iter 1 / 6 | time 1[s] | loss 0.51\n",
      "| epoch 695 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 696 |  iter 1 / 6 | time 1[s] | loss 0.23\n",
      "| epoch 697 |  iter 1 / 6 | time 1[s] | loss 0.50\n",
      "| epoch 698 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 699 |  iter 1 / 6 | time 1[s] | loss 0.38\n",
      "| epoch 700 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 701 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 702 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 703 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 704 |  iter 1 / 6 | time 1[s] | loss 0.32\n",
      "| epoch 705 |  iter 1 / 6 | time 1[s] | loss 0.45\n",
      "| epoch 706 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 707 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 708 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 709 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 710 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 711 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 712 |  iter 1 / 6 | time 1[s] | loss 0.34\n",
      "| epoch 713 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 714 |  iter 1 / 6 | time 1[s] | loss 0.33\n",
      "| epoch 715 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 716 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 717 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 718 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 719 |  iter 1 / 6 | time 1[s] | loss 0.33\n",
      "| epoch 720 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 721 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 722 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 723 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 724 |  iter 1 / 6 | time 1[s] | loss 0.28\n",
      "| epoch 725 |  iter 1 / 6 | time 1[s] | loss 0.32\n",
      "| epoch 726 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 727 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 728 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 729 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 730 |  iter 1 / 6 | time 1[s] | loss 0.31\n",
      "| epoch 731 |  iter 1 / 6 | time 1[s] | loss 0.43\n",
      "| epoch 732 |  iter 1 / 6 | time 1[s] | loss 0.33\n",
      "| epoch 733 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 734 |  iter 1 / 6 | time 1[s] | loss 0.35\n",
      "| epoch 735 |  iter 1 / 6 | time 1[s] | loss 0.49\n",
      "| epoch 736 |  iter 1 / 6 | time 1[s] | loss 0.32\n",
      "| epoch 737 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 738 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 739 |  iter 1 / 6 | time 1[s] | loss 0.30\n",
      "| epoch 740 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 741 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 742 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 743 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 744 |  iter 1 / 6 | time 1[s] | loss 0.34\n",
      "| epoch 745 |  iter 1 / 6 | time 1[s] | loss 0.47\n",
      "| epoch 746 |  iter 1 / 6 | time 1[s] | loss 0.35\n",
      "| epoch 747 |  iter 1 / 6 | time 1[s] | loss 0.33\n",
      "| epoch 748 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 749 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 750 |  iter 1 / 6 | time 1[s] | loss 0.33\n",
      "| epoch 751 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 752 |  iter 1 / 6 | time 1[s] | loss 0.42\n",
      "| epoch 753 |  iter 1 / 6 | time 1[s] | loss 0.30\n",
      "| epoch 754 |  iter 1 / 6 | time 1[s] | loss 0.46\n",
      "| epoch 755 |  iter 1 / 6 | time 1[s] | loss 0.28\n",
      "| epoch 756 |  iter 1 / 6 | time 1[s] | loss 0.32\n",
      "| epoch 757 |  iter 1 / 6 | time 1[s] | loss 0.40\n",
      "| epoch 758 |  iter 1 / 6 | time 1[s] | loss 0.31\n",
      "| epoch 759 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 760 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 761 |  iter 1 / 6 | time 1[s] | loss 0.31\n",
      "| epoch 762 |  iter 1 / 6 | time 1[s] | loss 0.35\n",
      "| epoch 763 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 764 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 765 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 766 |  iter 1 / 6 | time 1[s] | loss 0.36\n",
      "| epoch 767 |  iter 1 / 6 | time 1[s] | loss 0.35\n",
      "| epoch 768 |  iter 1 / 6 | time 1[s] | loss 0.41\n",
      "| epoch 769 |  iter 1 / 6 | time 1[s] | loss 0.33\n",
      "| epoch 770 |  iter 1 / 6 | time 1[s] | loss 0.38\n",
      "| epoch 771 |  iter 1 / 6 | time 1[s] | loss 0.33\n",
      "| epoch 772 |  iter 1 / 6 | time 1[s] | loss 0.30\n",
      "| epoch 773 |  iter 1 / 6 | time 1[s] | loss 0.38\n",
      "| epoch 774 |  iter 1 / 6 | time 1[s] | loss 0.26\n",
      "| epoch 775 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 776 |  iter 1 / 6 | time 1[s] | loss 0.28\n",
      "| epoch 777 |  iter 1 / 6 | time 1[s] | loss 0.33\n",
      "| epoch 778 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 779 |  iter 1 / 6 | time 1[s] | loss 0.34\n",
      "| epoch 780 |  iter 1 / 6 | time 1[s] | loss 0.39\n",
      "| epoch 781 |  iter 1 / 6 | time 1[s] | loss 0.31\n",
      "| epoch 782 |  iter 1 / 6 | time 1[s] | loss 0.37\n",
      "| epoch 783 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 784 |  iter 1 / 6 | time 2[s] | loss 0.35\n",
      "| epoch 785 |  iter 1 / 6 | time 2[s] | loss 0.30\n",
      "| epoch 786 |  iter 1 / 6 | time 2[s] | loss 0.40\n",
      "| epoch 787 |  iter 1 / 6 | time 2[s] | loss 0.41\n",
      "| epoch 788 |  iter 1 / 6 | time 2[s] | loss 0.28\n",
      "| epoch 789 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 790 |  iter 1 / 6 | time 2[s] | loss 0.39\n",
      "| epoch 791 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 792 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 793 |  iter 1 / 6 | time 2[s] | loss 0.40\n",
      "| epoch 794 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 795 |  iter 1 / 6 | time 2[s] | loss 0.37\n",
      "| epoch 796 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 797 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 798 |  iter 1 / 6 | time 2[s] | loss 0.35\n",
      "| epoch 799 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 800 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 801 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 802 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 803 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 804 |  iter 1 / 6 | time 2[s] | loss 0.41\n",
      "| epoch 805 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 806 |  iter 1 / 6 | time 2[s] | loss 0.35\n",
      "| epoch 807 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 808 |  iter 1 / 6 | time 2[s] | loss 0.34\n",
      "| epoch 809 |  iter 1 / 6 | time 2[s] | loss 0.30\n",
      "| epoch 810 |  iter 1 / 6 | time 2[s] | loss 0.35\n",
      "| epoch 811 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 812 |  iter 1 / 6 | time 2[s] | loss 0.39\n",
      "| epoch 813 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 814 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 815 |  iter 1 / 6 | time 2[s] | loss 0.40\n",
      "| epoch 816 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 817 |  iter 1 / 6 | time 2[s] | loss 0.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 818 |  iter 1 / 6 | time 2[s] | loss 0.34\n",
      "| epoch 819 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 820 |  iter 1 / 6 | time 2[s] | loss 0.38\n",
      "| epoch 821 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 822 |  iter 1 / 6 | time 2[s] | loss 0.37\n",
      "| epoch 823 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 824 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 825 |  iter 1 / 6 | time 2[s] | loss 0.41\n",
      "| epoch 826 |  iter 1 / 6 | time 2[s] | loss 0.28\n",
      "| epoch 827 |  iter 1 / 6 | time 2[s] | loss 0.36\n",
      "| epoch 828 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 829 |  iter 1 / 6 | time 2[s] | loss 0.35\n",
      "| epoch 830 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 831 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 832 |  iter 1 / 6 | time 2[s] | loss 0.37\n",
      "| epoch 833 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 834 |  iter 1 / 6 | time 2[s] | loss 0.30\n",
      "| epoch 835 |  iter 1 / 6 | time 2[s] | loss 0.34\n",
      "| epoch 836 |  iter 1 / 6 | time 2[s] | loss 0.30\n",
      "| epoch 837 |  iter 1 / 6 | time 2[s] | loss 0.36\n",
      "| epoch 838 |  iter 1 / 6 | time 2[s] | loss 0.28\n",
      "| epoch 839 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 840 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 841 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 842 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 843 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 844 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 845 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 846 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 847 |  iter 1 / 6 | time 2[s] | loss 0.36\n",
      "| epoch 848 |  iter 1 / 6 | time 2[s] | loss 0.17\n",
      "| epoch 849 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 850 |  iter 1 / 6 | time 2[s] | loss 0.25\n",
      "| epoch 851 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 852 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 853 |  iter 1 / 6 | time 2[s] | loss 0.35\n",
      "| epoch 854 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 855 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 856 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 857 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 858 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 859 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 860 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 861 |  iter 1 / 6 | time 2[s] | loss 0.43\n",
      "| epoch 862 |  iter 1 / 6 | time 2[s] | loss 0.21\n",
      "| epoch 863 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 864 |  iter 1 / 6 | time 2[s] | loss 0.30\n",
      "| epoch 865 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 866 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 867 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 868 |  iter 1 / 6 | time 2[s] | loss 0.25\n",
      "| epoch 869 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 870 |  iter 1 / 6 | time 2[s] | loss 0.34\n",
      "| epoch 871 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 872 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 873 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 874 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 875 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 876 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 877 |  iter 1 / 6 | time 2[s] | loss 0.28\n",
      "| epoch 878 |  iter 1 / 6 | time 2[s] | loss 0.19\n",
      "| epoch 879 |  iter 1 / 6 | time 2[s] | loss 0.25\n",
      "| epoch 880 |  iter 1 / 6 | time 2[s] | loss 0.35\n",
      "| epoch 881 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 882 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 883 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 884 |  iter 1 / 6 | time 2[s] | loss 0.25\n",
      "| epoch 885 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 886 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 887 |  iter 1 / 6 | time 2[s] | loss 0.21\n",
      "| epoch 888 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 889 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 890 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 891 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 892 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 893 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 894 |  iter 1 / 6 | time 2[s] | loss 0.30\n",
      "| epoch 895 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 896 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 897 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 898 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 899 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 900 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 901 |  iter 1 / 6 | time 2[s] | loss 0.28\n",
      "| epoch 902 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 903 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 904 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 905 |  iter 1 / 6 | time 2[s] | loss 0.18\n",
      "| epoch 906 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 907 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 908 |  iter 1 / 6 | time 2[s] | loss 0.17\n",
      "| epoch 909 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 910 |  iter 1 / 6 | time 2[s] | loss 0.33\n",
      "| epoch 911 |  iter 1 / 6 | time 2[s] | loss 0.19\n",
      "| epoch 912 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 913 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 914 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 915 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 916 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 917 |  iter 1 / 6 | time 2[s] | loss 0.19\n",
      "| epoch 918 |  iter 1 / 6 | time 2[s] | loss 0.32\n",
      "| epoch 919 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 920 |  iter 1 / 6 | time 2[s] | loss 0.20\n",
      "| epoch 921 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 922 |  iter 1 / 6 | time 2[s] | loss 0.19\n",
      "| epoch 923 |  iter 1 / 6 | time 2[s] | loss 0.30\n",
      "| epoch 924 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 925 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 926 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 927 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 928 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 929 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 930 |  iter 1 / 6 | time 2[s] | loss 0.19\n",
      "| epoch 931 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 932 |  iter 1 / 6 | time 2[s] | loss 0.30\n",
      "| epoch 933 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 934 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 935 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 936 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 937 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 938 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 939 |  iter 1 / 6 | time 2[s] | loss 0.30\n",
      "| epoch 940 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 941 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 942 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 943 |  iter 1 / 6 | time 2[s] | loss 0.28\n",
      "| epoch 944 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 945 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 946 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 947 |  iter 1 / 6 | time 2[s] | loss 0.35\n",
      "| epoch 948 |  iter 1 / 6 | time 2[s] | loss 0.21\n",
      "| epoch 949 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 950 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 951 |  iter 1 / 6 | time 2[s] | loss 0.35\n",
      "| epoch 952 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 953 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 954 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 955 |  iter 1 / 6 | time 2[s] | loss 0.34\n",
      "| epoch 956 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 957 |  iter 1 / 6 | time 2[s] | loss 0.20\n",
      "| epoch 958 |  iter 1 / 6 | time 2[s] | loss 0.26\n",
      "| epoch 959 |  iter 1 / 6 | time 2[s] | loss 0.17\n",
      "| epoch 960 |  iter 1 / 6 | time 2[s] | loss 0.31\n",
      "| epoch 961 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 962 |  iter 1 / 6 | time 2[s] | loss 0.20\n",
      "| epoch 963 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 964 |  iter 1 / 6 | time 2[s] | loss 0.28\n",
      "| epoch 965 |  iter 1 / 6 | time 2[s] | loss 0.16\n",
      "| epoch 966 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 967 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 968 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 969 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 970 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 971 |  iter 1 / 6 | time 2[s] | loss 0.22\n",
      "| epoch 972 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 973 |  iter 1 / 6 | time 2[s] | loss 0.34\n",
      "| epoch 974 |  iter 1 / 6 | time 2[s] | loss 0.18\n",
      "| epoch 975 |  iter 1 / 6 | time 2[s] | loss 0.25\n",
      "| epoch 976 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 977 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 978 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 979 |  iter 1 / 6 | time 2[s] | loss 0.21\n",
      "| epoch 980 |  iter 1 / 6 | time 2[s] | loss 0.28\n",
      "| epoch 981 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 982 |  iter 1 / 6 | time 2[s] | loss 0.15\n",
      "| epoch 983 |  iter 1 / 6 | time 2[s] | loss 0.25\n",
      "| epoch 984 |  iter 1 / 6 | time 2[s] | loss 0.23\n",
      "| epoch 985 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 986 |  iter 1 / 6 | time 2[s] | loss 0.15\n",
      "| epoch 987 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 988 |  iter 1 / 6 | time 2[s] | loss 0.25\n",
      "| epoch 989 |  iter 1 / 6 | time 2[s] | loss 0.25\n",
      "| epoch 990 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 991 |  iter 1 / 6 | time 2[s] | loss 0.20\n",
      "| epoch 992 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 993 |  iter 1 / 6 | time 2[s] | loss 0.21\n",
      "| epoch 994 |  iter 1 / 6 | time 2[s] | loss 0.29\n",
      "| epoch 995 |  iter 1 / 6 | time 2[s] | loss 0.18\n",
      "| epoch 996 |  iter 1 / 6 | time 2[s] | loss 0.21\n",
      "| epoch 997 |  iter 1 / 6 | time 2[s] | loss 0.27\n",
      "| epoch 998 |  iter 1 / 6 | time 2[s] | loss 0.19\n",
      "| epoch 999 |  iter 1 / 6 | time 2[s] | loss 0.24\n",
      "| epoch 1000 |  iter 1 / 6 | time 2[s] | loss 0.28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "from simple_cbow import SimpleCBOW\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'I like soccer but I have not play soccer. You are very exciting basketball player because You are nice face'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "model = SimpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "517a8b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i [ 0.6097749  -3.1493602  -0.75918895 -0.26312768  1.8102301 ]\n",
      "like [ 1.4184234  1.2361099 -1.5371615  1.2414654  1.4674406]\n",
      "soccer [ 2.9283605 -1.7467073 -2.960654  -2.5136132 -1.5338169]\n",
      "but [ 1.4501611   1.0510479  -0.11471695  1.9395049  -0.20296848]\n",
      "have [ 1.5856143  1.2530556  2.3547957  1.3609055 -2.264198 ]\n",
      "not [ 2.3605995 -1.3056164  1.7686068 -2.4470396  2.5558157]\n",
      "play [ 2.2182832   2.0310576   0.10165245  1.1388326  -0.14102069]\n",
      ". [ 0.27451193  0.00803026 -2.2123034   1.6443027   1.8276426 ]\n",
      "you [-1.6289426  2.2514718 -1.0458579 -2.29439   -2.4768593]\n",
      "are [-2.1125045  -2.6113813  -0.37105328  2.8677652   0.49933243]\n",
      "very [-1.2112089   2.1958861   0.37542337 -1.8358229   0.5532861 ]\n",
      "exciting [ 0.32555702 -2.660545    1.5998807   1.5455946  -2.9223595 ]\n",
      "basketball [-1.4678179  2.1981611  1.7223603 -0.5036532  2.2458293]\n",
      "player [-1.1770086 -2.1531217  2.4813752 -1.8637502 -2.3671596]\n",
      "because [-2.105221    0.40867546 -2.0575197   2.061165    2.060829  ]\n",
      "nice [-1.8011782   1.7558753  -1.3133249  -0.5854349  -0.43267593]\n",
      "face [-2.0564637   0.05120492  2.3301342   2.0804589   0.35695276]\n"
     ]
    }
   ],
   "source": [
    "# 学習済み重みパラメータを見てみる\n",
    "word_vecs = model.word_vecs\n",
    "\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad65383",
   "metadata": {},
   "source": [
    "## 3.5 word2vecに関する補足"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37702e45",
   "metadata": {},
   "source": [
    "### 3.5.1 CBOWモデルと確率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fff124",
   "metadata": {},
   "source": [
    "#### CBOWモデルの式\n",
    "## $$\n",
    "   P(w_t|w_{t-1}, w_{t+1})\n",
    "$$\n",
    "\n",
    "意味：$w_{t-1}とw_{t+1}$が与えられたときに$w_t$が起こる確率\n",
    "\n",
    "#### CBOWモデルの損失関数の式\n",
    "## $$\n",
    "   L = -\\frac{1}{T}\\sum_{t=1}^{T}logP(w_t|w_{t-1}, w_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc724e2",
   "metadata": {},
   "source": [
    "### 3.5.2 skip-gramモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671db318",
   "metadata": {},
   "source": [
    "skip-gramはCBOWで扱うコンテキストとターゲットを逆転させたモデルである．したがって入力層が一つ，そして出力層はコンテキストの数だけ存在する．出力層では個別に損失を求め，それらを足し合わせたものを最終的な損失とする．\n",
    "\n",
    "#### skip-gramの式\n",
    "## $$\n",
    "P(w_{t-1}, w_{t+1}|w_t)\n",
    "$$\n",
    "\n",
    "#### 意味\n",
    "$w_t$が与えられたときに，$w_{t-1}$と$w_{t+1}$が同時に起こる確率\n",
    "\n",
    "#### 条件付き独立\n",
    "skip-gramモデルでは，コンテキストの単語の間に関連性がないと仮定して以下のように分解する．\n",
    "## $$\n",
    "P(w_{t-1}, w_{t+1}|w_t) = P(w_{t-1}|w_t)P(w_{t+1}|w_t)\n",
    "$$\n",
    "\n",
    "#### コーパス全体のskip-gramモデルの損失関数\n",
    "## $$\n",
    "L = -logP(w_{t-1}, w_{t+1}|w_t)\n",
    "  = -logP(w_{t-1}|w_t)P(w_{t+1}|w_t)\n",
    "  = -(logP(w_{t-1}|w_t)+logP(w_{t+1}|w_t))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee0ecc",
   "metadata": {},
   "source": [
    "### 3.5.3 カウントベース v.s 推論ベース"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db96e38",
   "metadata": {},
   "source": [
    "## 3.6 まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e1e2e2",
   "metadata": {},
   "source": [
    "- 推論ベースの手法は，推測することを目標として，その副産物として単語の分散表現を得られる\n",
    "- word2vecは推論ベースの手法であり，シンプルな2層のニューラルネットワークで構成される\n",
    "- word2vecには，skig-gramモデルとCBOWモデルがある\n",
    "- CBOWモデルは複数の単語（コンテキスト）から一つの単語（ターゲット）を推測する\n",
    "- skip-gramモデルは逆に，一つの単語（ターゲット）から複数の単語（コンテキスト）を推測する\n",
    "- word2vecは重みの再学習ができるため，単語の分散表現の更新や追加が効率的に行える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e22c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
